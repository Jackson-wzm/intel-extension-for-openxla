diff --git a/t5x/contrib/calm/models.py b/t5x/contrib/calm/models.py
index d87922e..4332e4c 100644
--- a/t5x/contrib/calm/models.py
+++ b/t5x/contrib/calm/models.py
@@ -72,10 +72,16 @@ class DecodeFnCallable(typing_extensions.Protocol):
   """Decoding function call signature."""
 
   def __call__(
-      self, *, inputs: jnp.ndarray, cache: Mapping[str, jnp.ndarray],
-      tokens_to_logits: TokensIdsToLogitsCallable, eos_id: int,
-      num_decodes: int, decode_rng: Optional[jax.random.KeyArray],
-      cache_offset: int, **kwargs
+      self,
+      *,
+      inputs: jnp.ndarray,
+      cache: Mapping[str, jnp.ndarray],
+      tokens_to_logits: TokensIdsToLogitsCallable,
+      eos_id: int,
+      num_decodes: int,
+      decode_rng: Optional[jax.Array],
+      cache_offset: int,
+      **kwargs,
   ) -> Tuple[jnp.ndarray, Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]]:
     """Decoding function interface.
 
@@ -790,7 +796,7 @@ class EncoderDecoderModel(models.EncoderDecoderModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
       decoder_params: Optional[MutableMapping[str, Any]] = None,
       return_all_decodes: bool = False,
       num_decodes: int = 1,
diff --git a/t5x/contrib/moe/models.py b/t5x/contrib/moe/models.py
index 51e5b1c..3bf7d74 100644
--- a/t5x/contrib/moe/models.py
+++ b/t5x/contrib/moe/models.py
@@ -116,7 +116,7 @@ class MoeEncoderDecoderModel(base_models.EncoderDecoderModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
       decoder_params: Optional[MutableMapping[str, Any]] = None,
       return_all_decodes: bool = False,
       num_decodes: int = 1,
@@ -221,7 +221,7 @@ class MoeDecoderOnlyModel(base_models.DecoderOnlyModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
       *,
       return_all_decodes: bool = False,
       num_decodes: int = 1,
diff --git a/t5x/models.py b/t5x/models.py
index df07d24..9449d8d 100644
--- a/t5x/models.py
+++ b/t5x/models.py
@@ -78,7 +78,7 @@ class DecodeFnCallable(typing_extensions.Protocol):
       tokens_to_logits: TokensIdsToLogitsCallable,
       eos_id: int,
       num_decodes: int,
-      decode_rng: Optional[jax.random.KeyArray],
+      decode_rng: Optional[jax.Array],
       cache_offset: int,
       **kwargs,
   ) -> Tuple[jnp.ndarray, jnp.ndarray]:
@@ -131,7 +131,7 @@ class BaseModel(abc.ABC):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      dropout_rng: Optional[jax.random.KeyArray],
+      dropout_rng: Optional[jax.Array],
   ) -> Tuple[jnp.ndarray, MetricsMap]:
     """Computes loss and metrics.
 
@@ -175,7 +175,7 @@ class BaseModel(abc.ABC):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
   ) -> jnp.ndarray:
     """Predicts a batch of outputs from the model.
 
@@ -194,7 +194,7 @@ class BaseModel(abc.ABC):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
   ) -> Tuple[jnp.ndarray, Mapping[str, jnp.ndarray]]:
     """Predict a batch from the modelwith auxiliary outputs.
 
@@ -222,7 +222,7 @@ class BaseModel(abc.ABC):
   @abc.abstractmethod
   def get_initial_variables(
       self,
-      rng: jax.random.KeyArray,
+      rng: jax.Array,
       input_shapes: Mapping[str, Array],
       input_types: Optional[Mapping[str, jnp.dtype]] = None,
   ) -> flax_scope.FrozenVariableDict:
@@ -277,7 +277,7 @@ class BaseTransformerModel(BaseModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      dropout_rng: Optional[jax.random.KeyArray] = None,
+      dropout_rng: Optional[jax.Array] = None,
   ) -> jnp.ndarray:
     """Computes logits via a forward pass of the model."""
     pass
@@ -286,7 +286,7 @@ class BaseTransformerModel(BaseModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      dropout_rng: Optional[jax.random.KeyArray],
+      dropout_rng: Optional[jax.Array],
   ) -> Tuple[jnp.ndarray, MetricsMap]:
     """Loss function used for training with a cross-entropy loss."""
     logits = self._compute_logits(params, batch, dropout_rng)
@@ -390,7 +390,7 @@ class EncoderDecoderModel(BaseTransformerModel):
 
   def get_initial_variables(
       self,
-      rng: jax.random.KeyArray,
+      rng: jax.Array,
       input_shapes: Mapping[str, Array],
       input_types: Optional[Mapping[str, jnp.dtype]] = None,
   ) -> flax_scope.FrozenVariableDict:
@@ -448,7 +448,7 @@ class EncoderDecoderModel(BaseTransformerModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      dropout_rng: Optional[jax.random.KeyArray] = None,
+      dropout_rng: Optional[jax.Array] = None,
       mutable: flax_scope.CollectionFilter = False,
       other_variables: Optional[PyTree] = None,
   ) -> Union[jnp.ndarray, Tuple[jnp.ndarray, flax_scope.FrozenVariableDict]]:
@@ -546,7 +546,7 @@ class EncoderDecoderModel(BaseTransformerModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
       decoder_params: Optional[MutableMapping[str, Any]] = None,
       return_all_decodes: bool = False,
       num_decodes: int = 1,
@@ -805,7 +805,7 @@ class DecoderOnlyModel(BaseTransformerModel):
 
   def get_initial_variables(
       self,
-      rng: jax.random.KeyArray,
+      rng: jax.Array,
       input_shapes: Mapping[str, Array],
       input_types: Optional[Mapping[str, jnp.dtype]] = None,
   ) -> flax_scope.FrozenVariableDict:
@@ -839,7 +839,7 @@ class DecoderOnlyModel(BaseTransformerModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      dropout_rng: Optional[jax.random.KeyArray] = None,
+      dropout_rng: Optional[jax.Array] = None,
       mutable: flax_scope.CollectionFilter = False,
       other_variables: Optional[PyTree] = None,
   ) -> jnp.ndarray:
@@ -1031,7 +1031,7 @@ class DecoderOnlyModel(BaseTransformerModel):
       self,
       params: PyTree,
       batch: Mapping[str, jnp.ndarray],
-      rng: Optional[jax.random.KeyArray] = None,
+      rng: Optional[jax.Array] = None,
       *,
       return_all_decodes: bool = False,
       num_decodes: int = 1,
